{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optimizer\n",
    "device = torch.device('mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    # CUDA 장치 이름 및 세부 정보 확인\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"Device: {device_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "def create_invalid_pose(keypoints, width, height, pose_type, frame_idx, total_frames):\n",
    "    \"\"\"\n",
    "    특정 운동 유형에 따른 잘못된 자세를 생성하며, 프레임 길이에 따라 변형 정도를 조정합니다.\n",
    "\n",
    "    Parameters:\n",
    "        keypoints (list): Mediapipe 랜드마크 리스트 (정규화된 값).\n",
    "        width (int): 영상의 너비 (픽셀 기준).\n",
    "        height (int): 영상의 높이 (픽셀 기준).\n",
    "        pose_type (str): 운동 유형 (\"lunge\", \"pushup\", \"squat\").\n",
    "        frame_idx (int): 현재 프레임 인덱스.\n",
    "        total_frames (int): 해당 영상의 총 프레임 수.\n",
    "    \n",
    "    Returns:\n",
    "        invalid_keypoints_px (list): 변형된 자세의 픽셀 좌표 리스트.\n",
    "    \"\"\"\n",
    "    invalid_keypoints = []\n",
    "\n",
    "    # 변형 강도를 프레임 기반으로 조정\n",
    "    progress = frame_idx / total_frames  # 진행률 (0에서 1 사이)\n",
    "    intensity = abs(np.sin(progress * np.pi))  # 0 -> 1 -> 0 패턴 생성\n",
    "\n",
    "    for idx, landmark in enumerate(keypoints):\n",
    "        x, y, z = landmark.x, landmark.y, landmark.z  # 정규화된 좌표\n",
    "\n",
    "        if pose_type == \"lunge\":\n",
    "            if idx == mp_pose.PoseLandmark.LEFT_KNEE.value:\n",
    "                # 왼쪽 무릎: 왼쪽으로 더 이동\n",
    "                x -= intensity * np.random.uniform(0.02, 0.05)\n",
    "                y += intensity * np.random.uniform(0.02, 0.05)\n",
    "            elif idx == mp_pose.PoseLandmark.RIGHT_KNEE.value:\n",
    "            # 오른쪽 무릎: 오른쪽으로 더 이동\n",
    "                x += intensity * np.random.uniform(0.02, 0.05)\n",
    "                y += intensity * np.random.uniform(0.02, 0.05)\n",
    "            elif idx == mp_pose.PoseLandmark.LEFT_SHOULDER.value:\n",
    "                x -= intensity * np.random.uniform(0.03, 0.05)  # 왼쪽 어깨\n",
    "                y += intensity * np.random.uniform(-0.03, 0.03)\n",
    "            elif idx == mp_pose.PoseLandmark.RIGHT_SHOULDER.value:\n",
    "                x += intensity * np.random.uniform(0.03, 0.05)  # 오른쪽 어깨\n",
    "                y += intensity * np.random.uniform(-0.03, 0.03)\n",
    "\n",
    "        elif pose_type == \"pushup\":\n",
    "            if idx == mp_pose.PoseLandmark.LEFT_ELBOW.value:\n",
    "                x -= intensity * np.random.uniform(0.03, 0.05)  # 왼쪽 팔꿈치\n",
    "                y += intensity * np.random.uniform(0.02, 0.05)\n",
    "            elif idx == mp_pose.PoseLandmark.RIGHT_ELBOW.value:\n",
    "                x += intensity * np.random.uniform(0.03, 0.05)  # 오른쪽 팔꿈치\n",
    "                y += intensity * np.random.uniform(0.02, 0.05)\n",
    "            elif idx == mp_pose.PoseLandmark.LEFT_HIP.value:\n",
    "                x -= intensity * np.random.uniform(0.02, 0.04)  # 왼쪽 엉덩이\n",
    "                y += intensity * np.random.uniform(-0.03, 0.03)\n",
    "            elif idx == mp_pose.PoseLandmark.RIGHT_HIP.value:\n",
    "                x += intensity * np.random.uniform(0.02, 0.04)  # 오른쪽 엉덩이\n",
    "                y += intensity * np.random.uniform(-0.03, 0.03)\n",
    "\n",
    "        elif pose_type == \"squat\":\n",
    "            if idx == mp_pose.PoseLandmark.LEFT_KNEE.value:\n",
    "                x -= intensity * np.random.uniform(0.03, 0.06)  # 왼쪽 무릎\n",
    "                y += intensity * np.random.uniform(0.03, 0.03)\n",
    "            elif idx == mp_pose.PoseLandmark.RIGHT_KNEE.value:\n",
    "                x += intensity * np.random.uniform(0.03, 0.06)  # 오른쪽 무릎\n",
    "                y += intensity * np.random.uniform(0.03, 0.03)\n",
    "            elif idx == mp_pose.PoseLandmark.LEFT_HIP.value:\n",
    "                x -= intensity * np.random.uniform(0.03, 0.05)  # 왼쪽 엉덩이\n",
    "                y += intensity * np.random.uniform(-0.02, -0.05)\n",
    "            elif idx == mp_pose.PoseLandmark.RIGHT_HIP.value:\n",
    "                x += intensity * np.random.uniform(0.03, 0.05)  # 오른쪽 엉덩이\n",
    "                y += intensity * np.random.uniform(-0.02, -0.05)\n",
    "            elif idx == mp_pose.PoseLandmark.LEFT_SHOULDER.value:\n",
    "                x -= intensity * np.random.uniform(0.03, 0.05)  # 왼쪽 어깨\n",
    "                y += intensity * np.random.uniform(-0.02, -0.02)\n",
    "            elif idx == mp_pose.PoseLandmark.RIGHT_SHOULDER.value:\n",
    "                x += intensity * np.random.uniform(0.03, 0.05)  # 오른쪽 어깨\n",
    "                y += intensity * np.random.uniform(-0.02, -0.02)\n",
    "\n",
    "\n",
    "        invalid_keypoints.append((x, y, z))\n",
    "    \n",
    "    # 정규화된 좌표 -> 픽셀 좌표 변환\n",
    "    invalid_keypoints_px = [\n",
    "        (int(lm[0] * width), int(lm[1] * height)) for lm in invalid_keypoints\n",
    "    ]\n",
    "\n",
    "    return invalid_keypoints_px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검은 화면에 그래프만 남기기 - 영상 전체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe Pose 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    enable_segmentation=False,\n",
    "                    min_detection_confidence=0.5)\n",
    "\n",
    "\n",
    "# verbose 설정\n",
    "verbose = False  # 상세 로그 출력 여부\n",
    "\n",
    "# 비디오 파일 범위 처리 (운동_001.mp4부터 운동_100.mp4까지)\n",
    "for i in range(1, 101):\n",
    "    # 비디오 파일 경로 생성\n",
    "    video_file = f'{data}/{data}_{i:03d}.{extension}'\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        if verbose:\n",
    "            print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "    \n",
    "    # 영상 정보 가져오기\n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # 출력 파일 경로\n",
    "    out_correct= f'data/{data}_processed/{data}_graph_{i:03d}.mp4'\n",
    "    out_wrong = f'data/{data}_wrong/{data}_wrong_{i:03d}.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out= cv2.VideoWriter(out_correct, fourcc, fps, (w, h))\n",
    "    out_incorrect = cv2.VideoWriter(out_wrong, fourcc, fps, (w, h))\n",
    "    prev_time = 0\n",
    "    frame_idx = int(0)\n",
    "    # Mediapipe Pose 실행\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        \n",
    "        if not success or image is None:\n",
    "            if verbose:\n",
    "                print(f\"End of video {video_file}\")\n",
    "            break\n",
    "        \n",
    "        curr_time = time.time()\n",
    "        \n",
    "        # BGR 이미지를 RGB로 변환 후 처리\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # 검은 화면 생성\n",
    "        black_frame_correct = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        black_frame_incorrect = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        # 랜드마크 그리기\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                black_frame_correct, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2))\n",
    "        if results.pose_landmarks:\n",
    "            keypoints = results.pose_landmarks.landmark\n",
    "\n",
    "            #올바른 자세 그래프\n",
    "            mp_drawing.draw_landmarks(\n",
    "            black_frame_correct, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
    "            )\n",
    "\n",
    "    # 잘못된 자세 그래프\n",
    "        invalid_keypoints_px = create_invalid_pose(keypoints, w, h,data,int(frame_idx), int(fps))\n",
    "        for start, end in mp_pose.POSE_CONNECTIONS:\n",
    "            start_px, end_px = invalid_keypoints_px[start], invalid_keypoints_px[end]\n",
    "            cv2.line(black_frame_incorrect, start_px, end_px, (0, 255, 0), 2)\n",
    "\n",
    "        for point in invalid_keypoints_px:\n",
    "            cv2.circle(black_frame_incorrect, point, 3, (0, 255, 0), -1)\n",
    "        frame_idx +=1\n",
    "        #black_frame_correct = cv2.resize(black_frame_correct,(480,640))\n",
    "        #black_frame_incorrect = cv2.resize(black_frame_incorrect,(480,640))\n",
    "        # 출력 영상 저장 (화면 출력은 없음)\n",
    "        out.write(black_frame_correct)\n",
    "        out_incorrect.write(black_frame_incorrect)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    out_incorrect.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 파일 범위 처리\n",
    "for i in range(1, 101):\n",
    "    video_file = f'{data}/{data}_{i:03d}.{extension}'\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        if verbose:\n",
    "            print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "    \n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # 출력 파일 경로\n",
    "    out_correct_file = f'data/{data}_processed/{data}_correct_{i:03d}.mp4'\n",
    "    out_incorrect_file = f'data/{data}_processed/{data}_incorrect_{i:03d}.mp4'\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    out_correct = cv2.VideoWriter(out_correct_file, fourcc, fps, (w, h))\n",
    "    out_incorrect = cv2.VideoWriter(out_incorrect_file, fourcc, fps, (w, h))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success or image is None:\n",
    "            if verbose:\n",
    "                print(f\"End of video {video_file}\")\n",
    "            break\n",
    "        \n",
    "        # Mediapipe Pose 처리\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # 검은 화면 생성\n",
    "        black_frame_correct = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        black_frame_incorrect = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            # 랜드마크 가져오기\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # 올바른 자세 랜드마크 그리기\n",
    "            mp_drawing.draw_landmarks(\n",
    "                black_frame_correct, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2))\n",
    "            \n",
    "            # 잘못된 자세 생성 및 그리기\n",
    "            invalid_landmarks_px = create_invalid_pose(landmarks, w, h)\n",
    "            for start, end in mp_pose.POSE_CONNECTIONS:\n",
    "                start_px, end_px = invalid_landmarks_px[start], invalid_landmarks_px[end]\n",
    "                cv2.line(black_frame_incorrect, start_px, end_px, (0, 255, 0), 2)\n",
    "            \n",
    "            for point in invalid_landmarks_px:\n",
    "                cv2.circle(black_frame_incorrect, point, 3, (0,255, 0), -1)\n",
    "        black_frame_correct \n",
    "        # 각각의 영상 저장\n",
    "        out_correct.write(black_frame_correct)\n",
    "        out_incorrect.write(black_frame_incorrect)\n",
    "    \n",
    "    cap.release()\n",
    "    out_correct.release()\n",
    "    out_incorrect.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검은 화면에 그래프만 남기기 - 영상 초기 15프레임만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737334578.264220 55949771 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n",
      "OpenCV: Couldn't read video stream from file \"not/not_001.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_002.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_003.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_004.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_005.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_006.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_007.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_008.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_009.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_010.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_011.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_012.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_013.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_014.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_015.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_016.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_017.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_018.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_019.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_020.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_021.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_022.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_023.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_024.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_025.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_026.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_027.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_028.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_029.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_030.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_031.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_032.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_033.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_034.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_035.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_036.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_037.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_038.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_039.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_040.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_041.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_042.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_043.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_044.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_045.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_046.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_047.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_048.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_049.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_050.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_051.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_052.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_053.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_054.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_055.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_056.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_057.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_058.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_059.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_060.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_061.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_062.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_063.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_064.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_065.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_066.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_067.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_068.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_069.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_070.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_071.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_072.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_073.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_074.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_075.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_076.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_077.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_078.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_079.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_080.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_081.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_082.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_083.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_084.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_085.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_086.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_087.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_088.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_089.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_090.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_091.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_092.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_093.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_094.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_095.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_096.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_097.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_098.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_099.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"not/not_100.mp4\"\n",
      "W0000 00:00:1737334578.370372 55979715 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737334578.383811 55979715 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Mediapipe Pose 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# verbose 설정\n",
    "verbose = False  # 상세 로그 출력 여부\n",
    "data = \"not\"\n",
    "extension = \"mp4\"  # 비디오 파일 확장자\n",
    "\n",
    "# Pose 모델 초기화 (루프 바깥에서)\n",
    "pose = mp_pose.Pose(static_image_mode=False, \n",
    "                    model_complexity=1, \n",
    "                    enable_segmentation=False, \n",
    "                    min_detection_confidence=0.5)\n",
    "\n",
    "# 비디오 파일 범위 처리 (운동_001.mp4부터 운동_100.mp4까지)\n",
    "for i in range(1, 101):\n",
    "    # 비디오 파일 경로 생성\n",
    "    video_file = f'{data}/{data}_{i:03d}.{extension}'\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        if verbose:\n",
    "            print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "    \n",
    "    # 영상 정보 가져오기\n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # 출력 파일 경로\n",
    "    out_file = f'data/{data}_start/{data}_graph_start_{i:03d}.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(out_file, fourcc, fps, (w, h))\n",
    "    \n",
    "    prev_time = 0\n",
    "    frame_count = 0  # 프레임 카운트 변수\n",
    "    \n",
    "    # Mediapipe Pose 실행\n",
    "    while cap.isOpened() and frame_count < 15:  # 15프레임까지만 처리\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            if verbose:\n",
    "                print(f\"End of video {video_file}\")\n",
    "            break\n",
    "        \n",
    "        curr_time = time.time()\n",
    "        \n",
    "        # 검은 화면 생성\n",
    "        black_frame = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        \n",
    "        # BGR 이미지를 RGB로 변환 후 처리\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # 랜드마크 그리기\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                black_frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2))\n",
    "    \n",
    "        # 출력 영상 저장 (화면 출력은 없음)\n",
    "        out.write(black_frame)\n",
    "        \n",
    "        frame_count += 1  # 처리한 프레임 수 증가\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "# Pose 모델 종료\n",
    "pose.close()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹캠 영상 그래프로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe Pose 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, \n",
    "                    model_complexity=1, \n",
    "                    enable_segmentation=False, \n",
    "                    min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# 비디오 입력 설정\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # BGR 이미지를 RGB로 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Pose 추론\n",
    "    results = pose.process(rgb_frame)\n",
    "    \n",
    "    # 검은 화면 생성\n",
    "    black_frame = np.zeros((480, 640, 3), dtype=np.uint8)  # 480x640 해상도, 검은 배경\n",
    "    \n",
    "    # Pose 결과를 검은 화면에 그리기\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            black_frame, \n",
    "            results.pose_landmarks, \n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),  # 랜드마크 스타일\n",
    "            mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)  # 연결선 스타일\n",
    "        )\n",
    "    \n",
    "    # 결과 화면 출력\n",
    "    cv2.imshow('Pose Graph on Black Background', black_frame)\n",
    "    cv2.imshow('video',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):  # ESC 키로 종료\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상에서 노드와 엣지 추출(그래프 데이터로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'push'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# MediaPipe 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# 데이터 폴더 설정\n",
    "output_folder = f\"{data}_graph_folder\"  # 출력 폴더 (추출된 노드와 엣지를 저장)\n",
    "# 출력 폴더가 없으면 생성\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 비디오 파일 경로 설정 (data_001.mp4부터 data_101.mp4까지 처리)\n",
    "for i in range(1, 101):  # 1번부터 100번까지 처리\n",
    "    video_file = f\"{data}/{data}_{i:03d}.mov\"  # 비디오 파일 경로 생성\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "\n",
    "    # JSON 파일 생성 (노드 및 엣지 저장)\n",
    "    json_filename = os.path.join(output_folder, f\"{data}_{i:03d}_landmarks_edges.json\")\n",
    "    all_frames_data = []  # 모든 프레임 데이터를 저장할 리스트\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # 이미지를 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(rgb_frame)\n",
    "\n",
    "        frame_data = {\"frame\": frame_count, \"nodes\": [], \"edges\": []}  # 각 프레임 데이터 초기화\n",
    "\n",
    "        # Pose landmarks 추출\n",
    "        if result.pose_landmarks:\n",
    "            # 각 부위 (노드)의 좌표 저장\n",
    "            for i, landmark in enumerate(result.pose_landmarks.landmark):\n",
    "                node_data = {\"node_id\": i, \"x\": landmark.x, \"y\": landmark.y, \"z\": landmark.z}\n",
    "                frame_data[\"nodes\"].append(node_data)\n",
    "\n",
    "            # 엣지 추출: 인체 부위 간 연결\n",
    "            edges = [\n",
    "                (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW),\n",
    "                (mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW),\n",
    "                (mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST),\n",
    "                (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER),\n",
    "                # 추가적인 연결부위를 추가 가능\n",
    "            ]\n",
    "\n",
    "            # 엣지 정보 저장\n",
    "            for edge in edges:\n",
    "                start_node = result.pose_landmarks.landmark[edge[0]]\n",
    "                end_node = result.pose_landmarks.landmark[edge[1]]\n",
    "                edge_data = {\"start_node\": edge[0], \"end_node\": edge[1], \n",
    "                             \"start_x\": start_node.x, \"start_y\": start_node.y, \"start_z\": start_node.z,\n",
    "                             \"end_x\": end_node.x, \"end_y\": end_node.y, \"end_z\": end_node.z}\n",
    "                frame_data[\"edges\"].append(edge_data)\n",
    "\n",
    "        # 각 프레임 데이터를 리스트에 추가\n",
    "        all_frames_data.append(frame_data)\n",
    "\n",
    "    # JSON 파일에 전체 프레임 데이터 저장\n",
    "    with open(json_filename, 'w') as json_file:\n",
    "        json.dump(all_frames_data, json_file, indent=4)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General configuration for OpenCV 4.10.0 =====================================\n",
      "  Version control:               4.10.0\n",
      "\n",
      "  Extra modules:\n",
      "    Location (extra):            /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv_contrib/modules\n",
      "    Version control (extra):     4.10.0\n",
      "\n",
      "  Platform:\n",
      "    Timestamp:                   2024-06-17T18:17:11Z\n",
      "    Host:                        Darwin 20.2.0 arm64\n",
      "    CMake:                       3.20.3\n",
      "    CMake generator:             Unix Makefiles\n",
      "    CMake build tool:            /usr/bin/make\n",
      "    Configuration:               Release\n",
      "\n",
      "  CPU/HW features:\n",
      "    Baseline:                    NEON FP16\n",
      "    Dispatched code generation:  NEON_DOTPROD NEON_FP16 NEON_BF16\n",
      "      requested:                 NEON_FP16 NEON_BF16 NEON_DOTPROD\n",
      "      NEON_DOTPROD (1 files):    + NEON_DOTPROD\n",
      "      NEON_FP16 (2 files):       + NEON_FP16\n",
      "      NEON_BF16 (0 files):       + NEON_BF16\n",
      "\n",
      "  C/C++:\n",
      "    Built as dynamic libs?:      NO\n",
      "    C++ standard:                11\n",
      "    C++ Compiler:                /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++  (ver 12.0.5.12050022)\n",
      "    C++ flags (Release):         -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Qunused-arguments -Wno-semicolon-before-method-body -ffunction-sections -fdata-sections    -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG\n",
      "    C++ flags (Debug):           -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Qunused-arguments -Wno-semicolon-before-method-body -ffunction-sections -fdata-sections    -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG\n",
      "    C Compiler:                  /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc\n",
      "    C flags (Release):           -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Qunused-arguments -Wno-semicolon-before-method-body -ffunction-sections -fdata-sections    -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG\n",
      "    C flags (Debug):             -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Qunused-arguments -Wno-semicolon-before-method-body -ffunction-sections -fdata-sections    -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG\n",
      "    Linker flags (Release):      -Wl,-dead_strip  \n",
      "    Linker flags (Debug):        -Wl,-dead_strip  \n",
      "    ccache:                      YES\n",
      "    Precompiled headers:         NO\n",
      "    Extra dependencies:          -framework OpenCL /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX11.3.sdk/System/Library/Frameworks/Accelerate.framework -lm -ldl -framework Cocoa -framework AppKit Iconv::Iconv\n",
      "    3rdparty dependencies:       libprotobuf ade ittnotify libjpeg-turbo libwebp libpng libtiff libopenjp2 IlmImf zlib tegra_hal\n",
      "\n",
      "  OpenCV modules:\n",
      "    To be built:                 aruco bgsegm bioinspired calib3d ccalib core datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency shape signal stereo stitching structured_light superres surface_matching text tracking video videoio videostab wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto\n",
      "    Disabled:                    freetype world\n",
      "    Disabled by dependency:      -\n",
      "    Unavailable:                 alphamat cannops cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev cvv hdf java julia matlab ovis python2 sfm ts viz\n",
      "    Applications:                -\n",
      "    Documentation:               NO\n",
      "    Non-free algorithms:         NO\n",
      "\n",
      "  GUI:                           COCOA\n",
      "    Cocoa:                       YES\n",
      "    VTK support:                 NO\n",
      "\n",
      "  Media I/O: \n",
      "    ZLib:                        build (ver 1.3.1)\n",
      "    JPEG:                        build-libjpeg-turbo (ver 3.0.3-70)\n",
      "      SIMD Support Request:      YES\n",
      "      SIMD Support:              YES\n",
      "    WEBP:                        build (ver encoder: 0x020f)\n",
      "    PNG:                         build (ver 1.6.43)\n",
      "      SIMD Support Request:      YES\n",
      "      SIMD Support:              YES (Arm NEON)\n",
      "    TIFF:                        build (ver 42 - 4.6.0)\n",
      "    JPEG 2000:                   build (ver 2.5.0)\n",
      "    OpenEXR:                     build (ver 2.3.0)\n",
      "    HDR:                         YES\n",
      "    SUNRASTER:                   YES\n",
      "    PXM:                         YES\n",
      "    PFM:                         YES\n",
      "\n",
      "  Video I/O:\n",
      "    DC1394:                      NO\n",
      "    FFMPEG:                      YES\n",
      "      avcodec:                   YES (60.3.100)\n",
      "      avformat:                  YES (60.3.100)\n",
      "      avutil:                    YES (58.2.100)\n",
      "      swscale:                   YES (7.1.100)\n",
      "      avresample:                YES (4.0.0)\n",
      "    GStreamer:                   NO\n",
      "    AVFoundation:                YES\n",
      "\n",
      "  Parallel framework:            GCD\n",
      "\n",
      "  Trace:                         YES (with Intel ITT)\n",
      "\n",
      "  Other third-party libraries:\n",
      "    Lapack:                      YES (/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX11.3.sdk/System/Library/Frameworks/Accelerate.framework -lm -ldl)\n",
      "    Eigen:                       NO\n",
      "    Custom HAL:                  YES (carotene (ver 0.0.1, Auto detected))\n",
      "    Protobuf:                    build (3.19.1)\n",
      "    Flatbuffers:                 builtin/3rdparty (23.5.9)\n",
      "\n",
      "  OpenCL:                        YES (no extra features)\n",
      "    Include path:                NO\n",
      "    Link libraries:              -framework OpenCL\n",
      "\n",
      "  Python 3:\n",
      "    Interpreter:                 /Users/xperience/.pyenv/versions/3.9.5/bin/python3.9 (ver 3.9.5)\n",
      "    Libraries:                   /Users/xperience/.pyenv/versions/3.9.5/lib/libpython3.9.a (ver 3.9.5)\n",
      "    Limited API:                 YES (ver 0x03060000)\n",
      "    numpy:                       /Users/xperience/.pyenv/versions/3.9.5/lib/python3.9/site-packages/numpy/_core/include (ver 2.0.0)\n",
      "    install path:                python/cv2/python-3\n",
      "\n",
      "  Python (for build):            /Users/xperience/.pyenv/versions/3.9.5/bin/python3.9\n",
      "\n",
      "  Java:                          \n",
      "    ant:                         NO\n",
      "    Java:                        YES (ver 17.0.9)\n",
      "    JNI:                         NO\n",
      "    Java wrappers:               NO\n",
      "    Java tests:                  NO\n",
      "\n",
      "  Install to:                    /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/_skbuild/macosx-11.0-arm64-3.9/cmake-install\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldjins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
