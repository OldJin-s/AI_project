{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optimizer\n",
    "device = torch.device('cuda:0')\n",
    "input_size = 1\n",
    "hidden_size, latent_size = 1, 1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    # CUDA 장치 이름 및 세부 정보 확인\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"Device: {device_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검은 화면에 그래프만 남기기 - 영상 전체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe Pose 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    enable_segmentation=False,\n",
    "                    min_detection_confidence=0.5)\n",
    "\n",
    "# verbose 설정\n",
    "verbose = False  # 상세 로그 출력 여부\n",
    "data = \"squat\"\n",
    "extension = \"mp4\"  # 비디오 파일 확장자\n",
    "\n",
    "# 비디오 파일 범위 처리 (운동_001.mp4부터 운동_100.mp4까지)\n",
    "for i in range(1, 101):\n",
    "    # 비디오 파일 경로 생성\n",
    "    video_file = f'{data}/{data}_{i:03d}.{extension}'\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        if verbose:\n",
    "            print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "    \n",
    "    # 영상 정보 가져오기\n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # 출력 파일 경로\n",
    "    out_file = f'data/{data}_processed/{data}_graph_{i:03d}.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    out = cv2.VideoWriter(out_file, fourcc, fps, (w, h))\n",
    "    \n",
    "    prev_time = 0\n",
    "    \n",
    "    # Mediapipe Pose 실행\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success or image is None:\n",
    "            if verbose:\n",
    "                print(f\"End of video {video_file}\")\n",
    "            break\n",
    "        \n",
    "        curr_time = time.time()\n",
    "        \n",
    "        # BGR 이미지를 RGB로 변환 후 처리\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # 검은 화면 생성\n",
    "        black_frame = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        \n",
    "        # 랜드마크 그리기\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                black_frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2))\n",
    "        \n",
    "        # 출력 영상 저장 (화면 출력은 없음)\n",
    "        out.write(black_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검은 화면에 그래프만 남기기 - 영상 초기 15프레임만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe Pose 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# verbose 설정\n",
    "verbose = False  # 상세 로그 출력 여부\n",
    "data = \"not\"\n",
    "extension = \"mp4\"  # 비디오 파일 확장자\n",
    "\n",
    "# Pose 모델 초기화 (루프 바깥에서)\n",
    "pose = mp_pose.Pose(static_image_mode=False, \n",
    "                    model_complexity=1, \n",
    "                    enable_segmentation=False, \n",
    "                    min_detection_confidence=0.5)\n",
    "\n",
    "# 비디오 파일 범위 처리 (운동_001.mp4부터 운동_100.mp4까지)\n",
    "for i in range(1, 101):\n",
    "    # 비디오 파일 경로 생성\n",
    "    video_file = f'{data}/{data}_{i:03d}.{extension}'\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        if verbose:\n",
    "            print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "    \n",
    "    # 영상 정보 가져오기\n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # 출력 파일 경로\n",
    "    out_file = f'data/{data}_start/{data}_graph_start_{i:03d}.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    out = cv2.VideoWriter(out_file, fourcc, fps, (w, h))\n",
    "    \n",
    "    prev_time = 0\n",
    "    frame_count = 0  # 프레임 카운트 변수\n",
    "    \n",
    "    # Mediapipe Pose 실행\n",
    "    while cap.isOpened() and frame_count < 15:  # 15프레임까지만 처리\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            if verbose:\n",
    "                print(f\"End of video {video_file}\")\n",
    "            break\n",
    "        \n",
    "        curr_time = time.time()\n",
    "        \n",
    "        # 검은 화면 생성\n",
    "        black_frame = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        \n",
    "        # BGR 이미지를 RGB로 변환 후 처리\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # 랜드마크 그리기\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                black_frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2))\n",
    "    \n",
    "        # 출력 영상 저장 (화면 출력은 없음)\n",
    "        out.write(black_frame)\n",
    "        \n",
    "        frame_count += 1  # 처리한 프레임 수 증가\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "# Pose 모델 종료\n",
    "pose.close()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹캠 영상 그래프로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe Pose 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, \n",
    "                    model_complexity=1, \n",
    "                    enable_segmentation=False, \n",
    "                    min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# 비디오 입력 설정\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # BGR 이미지를 RGB로 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Pose 추론\n",
    "    results = pose.process(rgb_frame)\n",
    "    \n",
    "    # 검은 화면 생성\n",
    "    black_frame = np.zeros((480, 640, 3), dtype=np.uint8)  # 480x640 해상도, 검은 배경\n",
    "    \n",
    "    # Pose 결과를 검은 화면에 그리기\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            black_frame, \n",
    "            results.pose_landmarks, \n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),  # 랜드마크 스타일\n",
    "            mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)  # 연결선 스타일\n",
    "        )\n",
    "    \n",
    "    # 결과 화면 출력\n",
    "    cv2.imshow('Pose Graph on Black Background', black_frame)\n",
    "    cv2.imshow('video',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):  # ESC 키로 종료\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상에서 노드와 엣지 추출(그래프 데이터로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'push'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# MediaPipe 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# 데이터 폴더 설정\n",
    "output_folder = f\"{data}_graph_folder\"  # 출력 폴더 (추출된 노드와 엣지를 저장)\n",
    "# 출력 폴더가 없으면 생성\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 비디오 파일 경로 설정 (data_001.mp4부터 data_101.mp4까지 처리)\n",
    "for i in range(1, 101):  # 1번부터 100번까지 처리\n",
    "    video_file = f\"{data}/{data}_{i:03d}.mov\"  # 비디오 파일 경로 생성\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "\n",
    "    # JSON 파일 생성 (노드 및 엣지 저장)\n",
    "    json_filename = os.path.join(output_folder, f\"{data}_{i:03d}_landmarks_edges.json\")\n",
    "    all_frames_data = []  # 모든 프레임 데이터를 저장할 리스트\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # 이미지를 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(rgb_frame)\n",
    "\n",
    "        frame_data = {\"frame\": frame_count, \"nodes\": [], \"edges\": []}  # 각 프레임 데이터 초기화\n",
    "\n",
    "        # Pose landmarks 추출\n",
    "        if result.pose_landmarks:\n",
    "            # 각 부위 (노드)의 좌표 저장\n",
    "            for i, landmark in enumerate(result.pose_landmarks.landmark):\n",
    "                node_data = {\"node_id\": i, \"x\": landmark.x, \"y\": landmark.y, \"z\": landmark.z}\n",
    "                frame_data[\"nodes\"].append(node_data)\n",
    "\n",
    "            # 엣지 추출: 인체 부위 간 연결\n",
    "            edges = [\n",
    "                (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW),\n",
    "                (mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW),\n",
    "                (mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST),\n",
    "                (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER),\n",
    "                # 추가적인 연결부위를 추가 가능\n",
    "            ]\n",
    "\n",
    "            # 엣지 정보 저장\n",
    "            for edge in edges:\n",
    "                start_node = result.pose_landmarks.landmark[edge[0]]\n",
    "                end_node = result.pose_landmarks.landmark[edge[1]]\n",
    "                edge_data = {\"start_node\": edge[0], \"end_node\": edge[1], \n",
    "                             \"start_x\": start_node.x, \"start_y\": start_node.y, \"start_z\": start_node.z,\n",
    "                             \"end_x\": end_node.x, \"end_y\": end_node.y, \"end_z\": end_node.z}\n",
    "                frame_data[\"edges\"].append(edge_data)\n",
    "\n",
    "        # 각 프레임 데이터를 리스트에 추가\n",
    "        all_frames_data.append(frame_data)\n",
    "\n",
    "    # JSON 파일에 전체 프레임 데이터 저장\n",
    "    with open(json_filename, 'w') as json_file:\n",
    "        json.dump(all_frames_data, json_file, indent=4)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldjins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
