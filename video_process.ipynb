{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optimizer\n",
    "device = torch.device('cuda:0')\n",
    "input_size = 1\n",
    "hidden_size, latent_size = 1, 1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    # CUDA 장치 이름 및 세부 정보 확인\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"Device: {device_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'squat'\n",
    "extension = 'mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검은 화면에 그래프만 남기기 - 영상 전체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737171655.351863 54158547 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "W0000 00:00:1737171655.462310 54165259 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737171655.479766 54165260 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737171655.498866 54165262 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Closing SolutionBase._graph which is already None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 53\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# BGR 이미지를 RGB로 변환 후 처리\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpose_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# 랜드마크 그리기\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/OldJins/lib/python3.9/site-packages/mediapipe/python/solutions/pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m       \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/OldJins/lib/python3.9/site-packages/mediapipe/python/solution_base.py:316\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_graph is None in SolutionBase\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stream_name, data \u001b[38;5;129;01min\u001b[39;00m input_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mValueError\u001b[0m: _graph is None in SolutionBase",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 64\u001b[0m\n\u001b[1;32m     57\u001b[0m             mp_drawing\u001b[38;5;241m.\u001b[39mdraw_landmarks(\n\u001b[1;32m     58\u001b[0m                 black_frame, results\u001b[38;5;241m.\u001b[39mpose_landmarks, mp_pose\u001b[38;5;241m.\u001b[39mPOSE_CONNECTIONS,\n\u001b[1;32m     59\u001b[0m                 landmark_drawing_spec\u001b[38;5;241m=\u001b[39mmp_drawing\u001b[38;5;241m.\u001b[39mDrawingSpec(color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, circle_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     60\u001b[0m                 connection_drawing_spec\u001b[38;5;241m=\u001b[39mmp_drawing\u001b[38;5;241m.\u001b[39mDrawingSpec(color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;66;03m# 출력 영상 저장 (화면 출력은 없음)\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m         out\u001b[38;5;241m.\u001b[39mwrite(black_frame)\n\u001b[1;32m     66\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m     67\u001b[0m out\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/OldJins/lib/python3.9/site-packages/mediapipe/python/solution_base.py:604\u001b[0m, in \u001b[0;36mSolutionBase.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[1;32m    603\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Closes all the input sources and the graph.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 604\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/OldJins/lib/python3.9/site-packages/mediapipe/python/solution_base.py:361\u001b[0m, in \u001b[0;36mSolutionBase.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Closes all the input sources and the graph.\"\"\"\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 361\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClosing SolutionBase._graph which is already None\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Closing SolutionBase._graph which is already None"
     ]
    }
   ],
   "source": [
    "# Mediapipe Pose 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, \n",
    "                    model_complexity=1, \n",
    "                    enable_segmentation=False, \n",
    "                    min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# verbose 설정\n",
    "verbose = False  # 상세 로그 출력 여부\n",
    "data = \"squat\"\n",
    "extension = \"mp4\"  # 비디오 파일 확장자\n",
    "\n",
    "# 비디오 파일 범위 처리 (운동_001.mp4부터 운동_100.mp4까지)\n",
    "for i in range(1, 101):\n",
    "    # 비디오 파일 경로 생성\n",
    "    video_file = f'{data}/{data}_{i:03d}.{extension}'\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        if verbose:\n",
    "            print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "    \n",
    "    # 영상 정보 가져오기\n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # 출력 파일 경로\n",
    "    out_file = f'data/{data}_processed/{data}_graph_{i:03d}.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    out = cv2.VideoWriter(out_file, fourcc, fps, (w, h))\n",
    "    \n",
    "    prev_time = 0\n",
    "    \n",
    "    # Mediapipe Pose 실행\n",
    "    with pose as pose_model:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                if verbose:\n",
    "                    print(f\"End of video {video_file}\")\n",
    "                break\n",
    "            \n",
    "            curr_time = time.time()\n",
    "            \n",
    "            # 검은 화면 생성\n",
    "            black_frame = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "            \n",
    "            # BGR 이미지를 RGB로 변환 후 처리\n",
    "            results = pose_model.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            # 랜드마크 그리기\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    black_frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2))\n",
    "        \n",
    "            \n",
    "            # 출력 영상 저장 (화면 출력은 없음)\n",
    "            out.write(black_frame)\n",
    "            \n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe Holistic 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, \n",
    "                    model_complexity=1, \n",
    "                    enable_segmentation=False, \n",
    "                    min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# verbose 설정\n",
    "verbose = False  # 상세 로그 출력 여부\n",
    "data = \"push\"\n",
    "\n",
    "# 비디오 파일 범위 처리 (운동_001.mp4부터 운동_100.mp4까지)\n",
    "for i in range(1, 101):\n",
    "    # 비디오 파일 경로 생성\n",
    "    video_file = f'{data}/{data}_{i:03d}.{extension}'\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        if verbose:\n",
    "            print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # 영상 정보 가져오기\n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # 출력 파일 경로\n",
    "    out_file = f'data/{data}_processed/{data}_graph_{i:03d}.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    out = cv2.VideoWriter(out_file, fourcc, fps, (w, h))\n",
    "    \n",
    "    prev_time = 0\n",
    "    \n",
    "    # Mediapipe Holistic 실행\n",
    "    with pose() as holistic:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                if verbose:\n",
    "                    print(f\"End of video {video_file}\")\n",
    "                break\n",
    "            \n",
    "            curr_time = time.time()\n",
    "            \n",
    "            # 검은 화면 생성\n",
    "            black_frame = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "            \n",
    "            # BGR 이미지를 RGB로 변환 후 처리\n",
    "            results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            # 랜드마크 그리기\n",
    "            if results.left_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    black_frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            if results.right_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    black_frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            if results.face_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    black_frame, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    black_frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "            \n",
    "            # FPS 계산 및 표시\n",
    "            sec = curr_time - prev_time\n",
    "            prev_time = curr_time\n",
    "            fps = 1 / (sec)\n",
    "            fps_str = \"FPS : %0.1f\" % fps\n",
    "            cv2.putText(black_frame, fps_str, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # verbose가 True일 경우 FPS 출력\n",
    "            if verbose:\n",
    "                print(f\"Processing frame {i} - FPS: {fps_str}\")\n",
    "            \n",
    "            # 출력 영상 저장 (화면 출력은 없음)\n",
    "            out.write(black_frame)\n",
    "            \n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검은 화면에 그래프만 남기기 - 영상 초기 15프레임만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 파일 범위 처리 (운동_001.mp4부터 운동_100.mp4까지)\n",
    "for i in range(1, 101):\n",
    "    # 비디오 파일 경로 생성\n",
    "    video_file = f'{data}/{data}_{i:03d}.{extension}'\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "    \n",
    "    # 영상 정보 가져오기\n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # 출력 파일 경로\n",
    "    out_file = f'data/{data}_start/{data}_graph_start_{i:03d}.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    out = cv2.VideoWriter(out_file, fourcc, fps, (w, h))\n",
    "    \n",
    "    prev_time = 0\n",
    "    frame_count = 0  # 프레임 수 카운트\n",
    "    \n",
    "    # Mediapipe Holistic 실행\n",
    "    with mp_holistic.Holistic(\n",
    "        static_image_mode=True, min_detection_confidence=0.5, model_complexity=2) as holistic:\n",
    "        while cap.isOpened() and frame_count < 15:  # 첫 30프레임만 처리\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(f\"End of video {video_file}\")\n",
    "                break\n",
    "            \n",
    "            curr_time = time.time()\n",
    "            \n",
    "            # 검은 화면 생성\n",
    "            black_frame = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "            \n",
    "            # BGR 이미지를 RGB로 변환 후 처리\n",
    "            results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            # 랜드마크 그리기\n",
    "            if results.left_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    black_frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            if results.right_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    black_frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            if results.face_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    black_frame, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    black_frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "            \n",
    "            # FPS 계산 및 표시\n",
    "            sec = curr_time - prev_time\n",
    "            prev_time = curr_time\n",
    "            fps = 1 / (sec)\n",
    "            fps_str = \"FPS : %0.1f\" % fps\n",
    "            cv2.putText(black_frame, fps_str, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # 출력 영상 저장 (화면 출력은 없음)\n",
    "            out.write(black_frame)\n",
    "            \n",
    "            # 프레임 카운트 증가\n",
    "            frame_count += 1\n",
    "    print(f'{i:03d} saved')    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹캠 영상 그래프로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mediapipe Pose 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, \n",
    "                    model_complexity=1, \n",
    "                    enable_segmentation=False, \n",
    "                    min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# 비디오 입력 설정\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # BGR 이미지를 RGB로 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Pose 추론\n",
    "    results = pose.process(rgb_frame)\n",
    "    \n",
    "    # 검은 화면 생성\n",
    "    black_frame = np.zeros((480, 640, 3), dtype=np.uint8)  # 480x640 해상도, 검은 배경\n",
    "    \n",
    "    # Pose 결과를 검은 화면에 그리기\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            black_frame, \n",
    "            results.pose_landmarks, \n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),  # 랜드마크 스타일\n",
    "            mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)  # 연결선 스타일\n",
    "        )\n",
    "    \n",
    "    # 결과 화면 출력\n",
    "    cv2.imshow('Pose Graph on Black Background', black_frame)\n",
    "    cv2.imshow('video',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):  # ESC 키로 종료\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상에서 노드와 엣지 추출(그래프 데이터로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'push'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# MediaPipe 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# 데이터 폴더 설정\n",
    "output_folder = f\"{data}_graph_folder\"  # 출력 폴더 (추출된 노드와 엣지를 저장)\n",
    "# 출력 폴더가 없으면 생성\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 비디오 파일 경로 설정 (data_001.mp4부터 data_101.mp4까지 처리)\n",
    "for i in range(1, 101):  # 1번부터 100번까지 처리\n",
    "    video_file = f\"{data}/{data}_{i:03d}.mov\"  # 비디오 파일 경로 생성\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Cannot open video {video_file}\")\n",
    "        continue\n",
    "\n",
    "    # JSON 파일 생성 (노드 및 엣지 저장)\n",
    "    json_filename = os.path.join(output_folder, f\"{data}_{i:03d}_landmarks_edges.json\")\n",
    "    all_frames_data = []  # 모든 프레임 데이터를 저장할 리스트\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # 이미지를 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(rgb_frame)\n",
    "\n",
    "        frame_data = {\"frame\": frame_count, \"nodes\": [], \"edges\": []}  # 각 프레임 데이터 초기화\n",
    "\n",
    "        # Pose landmarks 추출\n",
    "        if result.pose_landmarks:\n",
    "            # 각 부위 (노드)의 좌표 저장\n",
    "            for i, landmark in enumerate(result.pose_landmarks.landmark):\n",
    "                node_data = {\"node_id\": i, \"x\": landmark.x, \"y\": landmark.y, \"z\": landmark.z}\n",
    "                frame_data[\"nodes\"].append(node_data)\n",
    "\n",
    "            # 엣지 추출: 인체 부위 간 연결\n",
    "            edges = [\n",
    "                (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW),\n",
    "                (mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST),\n",
    "                (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW),\n",
    "                (mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST),\n",
    "                (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER),\n",
    "                # 추가적인 연결부위를 추가 가능\n",
    "            ]\n",
    "\n",
    "            # 엣지 정보 저장\n",
    "            for edge in edges:\n",
    "                start_node = result.pose_landmarks.landmark[edge[0]]\n",
    "                end_node = result.pose_landmarks.landmark[edge[1]]\n",
    "                edge_data = {\"start_node\": edge[0], \"end_node\": edge[1], \n",
    "                             \"start_x\": start_node.x, \"start_y\": start_node.y, \"start_z\": start_node.z,\n",
    "                             \"end_x\": end_node.x, \"end_y\": end_node.y, \"end_z\": end_node.z}\n",
    "                frame_data[\"edges\"].append(edge_data)\n",
    "\n",
    "        # 각 프레임 데이터를 리스트에 추가\n",
    "        all_frames_data.append(frame_data)\n",
    "\n",
    "    # JSON 파일에 전체 프레임 데이터 저장\n",
    "    with open(json_filename, 'w') as json_file:\n",
    "        json.dump(all_frames_data, json_file, indent=4)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OldJins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
