{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('mps') if torch.mps.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape: torch.Size([37050, 10, 3])\n",
      "y_data shape: torch.Size([37050, 3])\n",
      "Sample input (X): tensor([[-0.6779, -1.7277,  0.9513],\n",
      "        [-0.6523, -1.1336,  0.8668],\n",
      "        [-0.5511, -0.7513,  0.2365],\n",
      "        [-0.4703, -0.3556,  0.0376],\n",
      "        [-0.1769, -0.1026, -0.0376],\n",
      "        [ 0.1769,  0.1026, -0.1189],\n",
      "        [ 0.4091,  0.2420, -1.0924],\n",
      "        [ 0.4890,  0.3829, -1.2436],\n",
      "        [ 0.9050,  0.5006, -1.0335],\n",
      "        [ 1.4893,  0.5572,  0.0708]])\n",
      "Sample output (y): tensor([0.5171, 0.5103, 0.0047])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import torch\n",
    "\n",
    "# CSV 파일 경로 리스트 (001.csv부터 101.csv까지)\n",
    "squat_file_paths = glob.glob('squat_csv_data/*.csv')  # 'path_to_files/'는 파일들이 저장된 디렉토리 경로입니다.\n",
    "\n",
    "# 슬라이딩 윈도우 크기\n",
    "window_size = 10\n",
    "stride = 1\n",
    "\n",
    "# 입력 데이터와 출력 데이터 저장 리스트\n",
    "squat_X_data = []\n",
    "squat_y_data = []\n",
    "\n",
    "# 각 파일을 처리\n",
    "for file_path in squat_file_paths:\n",
    "    # 파일 읽기\n",
    "    df = pd.read_csv(file_path, header=None, names=['frame', 'node_id', 'x', 'y', 'z'])\n",
    "    \n",
    "    # node_id 별로 데이터 그룹화\n",
    "    for node_id in df['node_id'].unique():\n",
    "        node_data = df[df['node_id'] == node_id].set_index('frame')[['x', 'y', 'z']]\n",
    "\n",
    "        # 슬라이딩 윈도우 적용\n",
    "        for start in range(0, len(node_data) - window_size):\n",
    "            end = start + window_size\n",
    "            # 입력값 (슬라이딩 윈도우)\n",
    "            window_input = node_data.iloc[start:end].values.astype('float64')\n",
    "\n",
    "            # 윈도우 별로 정규화\n",
    "            scaler = RobustScaler()\n",
    "            scaler_fitted =  scaler.fit(window_input)\n",
    "            window_input_normalized = scaler_fitted.transform(window_input)  # 각 윈도우별로 정규화\n",
    "            \n",
    "            # 출력값 (다음 시점의 (x, y, z) 값)\n",
    "            next_point = node_data.iloc[end].astype('float64')\n",
    "\n",
    "            squat_X_data.append(window_input_normalized)\n",
    "            squat_y_data.append(next_point.values)\n",
    "        \n",
    "# X_data는 입력값 (슬라이딩 윈도우)\n",
    "# y_data는 출력값 (다음 시점의 (x, y, z))\n",
    "\n",
    "# numpy 배열로 변환\n",
    "squat_X_data = torch.FloatTensor(np.array(squat_X_data))\n",
    "squat_y_data = torch.FloatTensor(np.array(squat_y_data))\n",
    "\n",
    "print(\"X_data shape:\", squat_X_data.shape)\n",
    "print(\"y_data shape:\", squat_y_data.shape)\n",
    "\n",
    "# 결과 예시 (슬라이딩 윈도우의 첫 번째와 두 번째 샘플)\n",
    "print(\"Sample input (X):\", squat_X_data[0])\n",
    "print(\"Sample output (y):\", squat_y_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMmodel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # LSTM 레이어\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size ,num_layers=2, batch_first=True)\n",
    "        \n",
    "        # 출력 레이어\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, 3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # LSTM 레이어 통과\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)  # lstm_out은 모든 시점의 출력\n",
    "        \n",
    "        # 마지막 시점의 출력만 사용\n",
    "        last_hidden_state = lstm_out[:, -1, :]  # (batch_size, hidden_size)\n",
    "        \n",
    "        # 출력 레이어 통과\n",
    "        output = self.linear(last_hidden_state)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "squat_train = TensorDataset(squat_X_data,squat_y_data)\n",
    "squat_dataloader = DataLoader(squat_train, batch_size = 256, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.043926749005913736\n",
      "model_saved\n",
      "Epoch [2/100], Loss: 0.01201409312639514\n",
      "model_saved\n",
      "Epoch [3/100], Loss: 0.011989818150498743\n",
      "model_saved\n",
      "Epoch [4/100], Loss: 0.011908176849628317\n",
      "model_saved\n",
      "Epoch [5/100], Loss: 0.011765012275106434\n",
      "model_saved\n",
      "Epoch [6/100], Loss: 0.011589674826647188\n",
      "model_saved\n",
      "Epoch [7/100], Loss: 0.01144298113850427\n",
      "model_saved\n",
      "Epoch [8/100], Loss: 0.011316695326040018\n",
      "model_saved\n",
      "Epoch [9/100], Loss: 0.011208913528264083\n",
      "model_saved\n",
      "Epoch [10/100], Loss: 0.01111174694037643\n",
      "model_saved\n",
      "Epoch [11/100], Loss: 0.011021128746456114\n",
      "model_saved\n",
      "Epoch [12/100], Loss: 0.010934824763058588\n",
      "model_saved\n",
      "Epoch [13/100], Loss: 0.010855206275551484\n",
      "model_saved\n",
      "Epoch [14/100], Loss: 0.010782366424220903\n",
      "model_saved\n",
      "Epoch [15/100], Loss: 0.010710760353711145\n",
      "model_saved\n",
      "Epoch [16/100], Loss: 0.010644454176634037\n",
      "model_saved\n",
      "Epoch [17/100], Loss: 0.010585242901639692\n",
      "model_saved\n",
      "Epoch [18/100], Loss: 0.010531430754104051\n",
      "model_saved\n",
      "Epoch [19/100], Loss: 0.010481649051131359\n",
      "model_saved\n",
      "Epoch [20/100], Loss: 0.010435116758313158\n",
      "model_saved\n",
      "Epoch [21/100], Loss: 0.010393012143221908\n",
      "model_saved\n",
      "Epoch [22/100], Loss: 0.010353081477484826\n",
      "model_saved\n",
      "Epoch [23/100], Loss: 0.0103148664042739\n",
      "model_saved\n",
      "Epoch [24/100], Loss: 0.01027712160881994\n",
      "model_saved\n",
      "Epoch [25/100], Loss: 0.010240216379792525\n",
      "model_saved\n",
      "Epoch [26/100], Loss: 0.010204737164593976\n",
      "model_saved\n",
      "Epoch [27/100], Loss: 0.010169979843214667\n",
      "model_saved\n",
      "Epoch [28/100], Loss: 0.010138118437266556\n",
      "model_saved\n",
      "Epoch [29/100], Loss: 0.010107669544181434\n",
      "model_saved\n",
      "Epoch [30/100], Loss: 0.010079189683792407\n",
      "model_saved\n",
      "Epoch [31/100], Loss: 0.01005133096738879\n",
      "model_saved\n",
      "Epoch [32/100], Loss: 0.010026310899712402\n",
      "model_saved\n",
      "Epoch [33/100], Loss: 0.010002528071596191\n",
      "model_saved\n",
      "Epoch [34/100], Loss: 0.009980436192889667\n",
      "model_saved\n",
      "Epoch [35/100], Loss: 0.009961500723749912\n",
      "model_saved\n",
      "Epoch [36/100], Loss: 0.0099400137615358\n",
      "model_saved\n",
      "Epoch [37/100], Loss: 0.009918281153358263\n",
      "model_saved\n",
      "Epoch [38/100], Loss: 0.009894713317846944\n",
      "model_saved\n",
      "Epoch [39/100], Loss: 0.009873610996673334\n",
      "model_saved\n",
      "Epoch [40/100], Loss: 0.009852525916207453\n",
      "model_saved\n",
      "Epoch [41/100], Loss: 0.009833043235643157\n",
      "model_saved\n",
      "Epoch [42/100], Loss: 0.009813713563349227\n",
      "model_saved\n",
      "Epoch [43/100], Loss: 0.009795449919805958\n",
      "model_saved\n",
      "Epoch [44/100], Loss: 0.009778367570633517\n",
      "model_saved\n",
      "Epoch [45/100], Loss: 0.009762652093094999\n",
      "model_saved\n",
      "Epoch [46/100], Loss: 0.009747429721956623\n",
      "model_saved\n",
      "Epoch [47/100], Loss: 0.009732432237922632\n",
      "model_saved\n",
      "Epoch [48/100], Loss: 0.009717821239911276\n",
      "model_saved\n",
      "Epoch [49/100], Loss: 0.00970383728051494\n",
      "model_saved\n",
      "Epoch [50/100], Loss: 0.00969141752073734\n",
      "model_saved\n",
      "Epoch [51/100], Loss: 0.00967866603670449\n",
      "model_saved\n",
      "Epoch [52/100], Loss: 0.00966618963645707\n",
      "model_saved\n",
      "Epoch [53/100], Loss: 0.009654295481420282\n",
      "model_saved\n",
      "Epoch [54/100], Loss: 0.009642124994946965\n",
      "model_saved\n",
      "Epoch [55/100], Loss: 0.009630344255731024\n",
      "model_saved\n",
      "Epoch [56/100], Loss: 0.009618755219632695\n",
      "model_saved\n",
      "Epoch [57/100], Loss: 0.009606913840077046\n",
      "model_saved\n",
      "Epoch [58/100], Loss: 0.00959407214139556\n",
      "model_saved\n",
      "Epoch [59/100], Loss: 0.009583028094393426\n",
      "model_saved\n",
      "Epoch [60/100], Loss: 0.009571950089443346\n",
      "model_saved\n",
      "Epoch [61/100], Loss: 0.00956201385706663\n",
      "model_saved\n",
      "Epoch [62/100], Loss: 0.009550991281867028\n",
      "model_saved\n",
      "Epoch [63/100], Loss: 0.009542329243287958\n",
      "model_saved\n",
      "Epoch [64/100], Loss: 0.009531533112749457\n",
      "model_saved\n",
      "Epoch [65/100], Loss: 0.009530050297877912\n",
      "model_saved\n",
      "Epoch [66/100], Loss: 0.009515124604362865\n",
      "model_saved\n",
      "Epoch [67/100], Loss: 0.009503151253186936\n",
      "model_saved\n",
      "Epoch [68/100], Loss: 0.00949133001107337\n",
      "model_saved\n",
      "Epoch [69/100], Loss: 0.009482224155538555\n",
      "model_saved\n",
      "Epoch [70/100], Loss: 0.009472208417117082\n",
      "model_saved\n",
      "Epoch [71/100], Loss: 0.009464939197140008\n",
      "model_saved\n",
      "Epoch [72/100], Loss: 0.00945387785483537\n",
      "model_saved\n",
      "Epoch [73/100], Loss: 0.009444636233343646\n",
      "model_saved\n",
      "Epoch [74/100], Loss: 0.009437526670958976\n",
      "model_saved\n",
      "Epoch [75/100], Loss: 0.009429473285402718\n",
      "model_saved\n",
      "Epoch [76/100], Loss: 0.009423929388666975\n",
      "model_saved\n",
      "Epoch [77/100], Loss: 0.00941745605127051\n",
      "model_saved\n",
      "Epoch [78/100], Loss: 0.009412786149387729\n",
      "model_saved\n",
      "Epoch [79/100], Loss: 0.009407664548027618\n",
      "model_saved\n",
      "Epoch [80/100], Loss: 0.009402616097238557\n",
      "model_saved\n",
      "Epoch [81/100], Loss: 0.009396876332125274\n",
      "model_saved\n",
      "Epoch [82/100], Loss: 0.0093933149915317\n",
      "model_saved\n",
      "Epoch [83/100], Loss: 0.00939037168141583\n",
      "model_saved\n",
      "Epoch [84/100], Loss: 0.009388300839105043\n",
      "model_saved\n",
      "Epoch [85/100], Loss: 0.009382964871374183\n",
      "model_saved\n",
      "Epoch [86/100], Loss: 0.009385492214290747\n",
      "Epoch [87/100], Loss: 0.009381277897748454\n",
      "model_saved\n",
      "Epoch [88/100], Loss: 0.009377613035833527\n",
      "model_saved\n",
      "Epoch [89/100], Loss: 0.00937433140673514\n",
      "model_saved\n",
      "Epoch [90/100], Loss: 0.009369962596623548\n",
      "model_saved\n",
      "Epoch [91/100], Loss: 0.009366472018882632\n",
      "model_saved\n",
      "Epoch [92/100], Loss: 0.009361186336147888\n",
      "model_saved\n",
      "Epoch [93/100], Loss: 0.009356738374857553\n",
      "model_saved\n",
      "Epoch [94/100], Loss: 0.009348787078312758\n",
      "model_saved\n",
      "Epoch [95/100], Loss: 0.009346687707022346\n",
      "model_saved\n",
      "Epoch [96/100], Loss: 0.009342998773630323\n",
      "model_saved\n",
      "Epoch [97/100], Loss: 0.009339526780591956\n",
      "model_saved\n",
      "Epoch [98/100], Loss: 0.009334684641839102\n",
      "model_saved\n",
      "Epoch [99/100], Loss: 0.00933029594799054\n",
      "model_saved\n",
      "Epoch [100/100], Loss: 0.00932527687882298\n",
      "model_saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LSTMmodel(3,10).to(device)\n",
    "def saveModel():\n",
    "    torch.save(model.state_dict(), f'model/squat_lstm_train.pt')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=1e-2)\n",
    "scheduler = CosineAnnealingLR(optimizer,T_max= 25, eta_min=1e-4)\n",
    "# 학습 루프\n",
    "epochs = 100\n",
    "min_loss = 1e+10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x, y in squat_dataloader:\n",
    "        input = x.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파\n",
    "        output = model(input)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(output,y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    mean_loss =running_loss / len(squat_dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(squat_dataloader)}\")\n",
    "    if min(mean_loss,min_loss) == mean_loss:\n",
    "        min_loss = mean_loss\n",
    "        print('model_saved')\n",
    "        saveModel()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape: torch.Size([78584, 10, 3])\n",
      "y_data shape: torch.Size([78584, 3])\n",
      "Sample input (X): tensor([[ 3.0200e-01, -6.6357e-01, -4.6360e-01],\n",
      "        [ 2.1074e-01, -5.3016e-01,  2.0356e-01],\n",
      "        [ 1.7761e-01, -4.3395e-01,  5.3460e-01],\n",
      "        [ 3.3921e-02, -1.1878e-01,  6.0931e-01],\n",
      "        [ 1.8143e-02,  1.1878e-01, -1.5214e+00],\n",
      "        [-1.8143e-02,  3.0013e-01, -6.0836e-01],\n",
      "        [-8.7580e-01,  6.3276e-01, -2.4669e-01],\n",
      "        [-8.0585e-01,  5.9590e-01, -2.0356e-01],\n",
      "        [-7.9417e+00,  5.5847e-01,  1.9459e+00],\n",
      "        [-2.2256e+01, -1.4112e+00,  2.4406e+00]])\n",
      "Sample output (y): tensor([0.7717, 0.5951, 0.3040])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import torch\n",
    "\n",
    "# CSV 파일 경로 리스트 (001.csv부터 101.csv까지)\n",
    "push_file_paths = glob.glob('push_csv_data/*.csv')  # 'path_to_files/'는 파일들이 저장된 디렉토리 경로입니다.\n",
    "\n",
    "# 슬라이딩 윈도우 크기\n",
    "window_size = 10\n",
    "stride = 1\n",
    "\n",
    "# 입력 데이터와 출력 데이터 저장 리스트\n",
    "push_X_data = []\n",
    "push_y_data = []\n",
    "\n",
    "# 각 파일을 처리\n",
    "for file_path in push_file_paths:\n",
    "    # 파일 읽기\n",
    "    df = pd.read_csv(file_path, header=None, names=['frame', 'node_id', 'x', 'y', 'z'])\n",
    "    \n",
    "    # node_id 별로 데이터 그룹화\n",
    "    for node_id in df['node_id'].unique():\n",
    "        node_data = df[df['node_id'] == node_id].set_index('frame')[['x', 'y', 'z']]\n",
    "\n",
    "        # 슬라이딩 윈도우 적용\n",
    "        for start in range(0, len(node_data) - window_size):\n",
    "            end = start + window_size\n",
    "            # 입력값 (슬라이딩 윈도우)\n",
    "            window_input = node_data.iloc[start:end].values.astype('float64')\n",
    "\n",
    "            # 윈도우 별로 정규화\n",
    "            scaler = RobustScaler()\n",
    "            scaler_fitted =  scaler.fit(window_input)\n",
    "            window_input_normalized = scaler_fitted.transform(window_input)  # 각 윈도우별로 정규화\n",
    "            \n",
    "            # 출력값 (다음 시점의 (x, y, z) 값)\n",
    "            next_point = node_data.iloc[end].astype('float64')\n",
    "\n",
    "            push_X_data.append(window_input_normalized)\n",
    "            push_y_data.append(next_point.values)\n",
    "        \n",
    "# X_data는 입력값 (슬라이딩 윈도우)\n",
    "# y_data는 출력값 (다음 시점의 (x, y, z))\n",
    "\n",
    "# numpy 배열로 변환\n",
    "push_X_data = torch.FloatTensor(np.array(push_X_data))\n",
    "push_y_data = torch.FloatTensor(np.array(push_y_data))\n",
    "\n",
    "print(\"X_data shape:\", push_X_data.shape)\n",
    "print(\"y_data shape:\", push_y_data.shape)\n",
    "\n",
    "# 결과 예시 (슬라이딩 윈도우의 첫 번째와 두 번째 샘플)\n",
    "print(\"Sample input (X):\", push_X_data[0])\n",
    "print(\"Sample output (y):\", push_y_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_train = TensorDataset(push_X_data,push_y_data)\n",
    "push_dataloader = DataLoader(push_train, batch_size = 256, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.08972724123648596\n",
      "model_saved\n",
      "Epoch [2/100], Loss: 0.052279996843432174\n",
      "model_saved\n",
      "Epoch [3/100], Loss: 0.05203852513107298\n",
      "model_saved\n",
      "Epoch [4/100], Loss: 0.05172862530252153\n",
      "model_saved\n",
      "Epoch [5/100], Loss: 0.051447449420375525\n",
      "model_saved\n",
      "Epoch [6/100], Loss: 0.05120818486819438\n",
      "model_saved\n",
      "Epoch [7/100], Loss: 0.051067558537367795\n",
      "model_saved\n",
      "Epoch [8/100], Loss: 0.05087043172968036\n",
      "model_saved\n",
      "Epoch [9/100], Loss: 0.05070180932199431\n",
      "model_saved\n",
      "Epoch [10/100], Loss: 0.05057348312160868\n",
      "model_saved\n",
      "Epoch [11/100], Loss: 0.050438211982044415\n",
      "model_saved\n",
      "Epoch [12/100], Loss: 0.05026689641396075\n",
      "model_saved\n",
      "Epoch [13/100], Loss: 0.05007265027648851\n",
      "model_saved\n",
      "Epoch [14/100], Loss: 0.04987538544649216\n",
      "model_saved\n",
      "Epoch [15/100], Loss: 0.04970048928590862\n",
      "model_saved\n",
      "Epoch [16/100], Loss: 0.04955407180171156\n",
      "model_saved\n",
      "Epoch [17/100], Loss: 0.04942322425629203\n",
      "model_saved\n",
      "Epoch [18/100], Loss: 0.04930761634563293\n",
      "model_saved\n",
      "Epoch [19/100], Loss: 0.049198663866311214\n",
      "model_saved\n",
      "Epoch [20/100], Loss: 0.049104766413593716\n",
      "model_saved\n",
      "Epoch [21/100], Loss: 0.04902728466493008\n",
      "model_saved\n",
      "Epoch [22/100], Loss: 0.04896815842873013\n",
      "model_saved\n",
      "Epoch [23/100], Loss: 0.04891068665826456\n",
      "model_saved\n",
      "Epoch [24/100], Loss: 0.04885448587918806\n",
      "model_saved\n",
      "Epoch [25/100], Loss: 0.04879324490974994\n",
      "model_saved\n",
      "Epoch [26/100], Loss: 0.048732836758080836\n",
      "model_saved\n",
      "Epoch [27/100], Loss: 0.048663683652768595\n",
      "model_saved\n",
      "Epoch [28/100], Loss: 0.048616641725895846\n",
      "model_saved\n",
      "Epoch [29/100], Loss: 0.048583636151365815\n",
      "model_saved\n",
      "Epoch [30/100], Loss: 0.04853782074295397\n",
      "model_saved\n",
      "Epoch [31/100], Loss: 0.048488384705789214\n",
      "model_saved\n",
      "Epoch [32/100], Loss: 0.04844332012235633\n",
      "model_saved\n",
      "Epoch [33/100], Loss: 0.048407287267112575\n",
      "model_saved\n",
      "Epoch [34/100], Loss: 0.04838195767144427\n",
      "model_saved\n",
      "Epoch [35/100], Loss: 0.04835001550651237\n",
      "model_saved\n",
      "Epoch [36/100], Loss: 0.048327687566535674\n",
      "model_saved\n",
      "Epoch [37/100], Loss: 0.04831581809087763\n",
      "model_saved\n",
      "Epoch [38/100], Loss: 0.04828671946005247\n",
      "model_saved\n",
      "Epoch [39/100], Loss: 0.048260829317404705\n",
      "model_saved\n",
      "Epoch [40/100], Loss: 0.04822634280346795\n",
      "model_saved\n",
      "Epoch [41/100], Loss: 0.0481843913659599\n",
      "model_saved\n",
      "Epoch [42/100], Loss: 0.048144653709514325\n",
      "model_saved\n",
      "Epoch [43/100], Loss: 0.04811850517794053\n",
      "model_saved\n",
      "Epoch [44/100], Loss: 0.04808214681787289\n",
      "model_saved\n",
      "Epoch [45/100], Loss: 0.048062731445151156\n",
      "model_saved\n",
      "Epoch [46/100], Loss: 0.0480428083044407\n",
      "model_saved\n",
      "Epoch [47/100], Loss: 0.04801635793637763\n",
      "model_saved\n",
      "Epoch [48/100], Loss: 0.04800945570304116\n",
      "model_saved\n",
      "Epoch [49/100], Loss: 0.047963620982578795\n",
      "model_saved\n",
      "Epoch [50/100], Loss: 0.04795377301082549\n",
      "model_saved\n",
      "Epoch [51/100], Loss: 0.04795355878539796\n",
      "model_saved\n",
      "Epoch [52/100], Loss: 0.04792951344108931\n",
      "model_saved\n",
      "Epoch [53/100], Loss: 0.0479239213359254\n",
      "model_saved\n",
      "Epoch [54/100], Loss: 0.04792066925608762\n",
      "model_saved\n",
      "Epoch [55/100], Loss: 0.0478857072473713\n",
      "model_saved\n",
      "Epoch [56/100], Loss: 0.0478529522319837\n",
      "model_saved\n",
      "Epoch [57/100], Loss: 0.04785028294317351\n",
      "model_saved\n",
      "Epoch [58/100], Loss: 0.04783956321557007\n",
      "model_saved\n",
      "Epoch [59/100], Loss: 0.04784494016246706\n",
      "Epoch [60/100], Loss: 0.04783090877465006\n",
      "model_saved\n",
      "Epoch [61/100], Loss: 0.04782187910629163\n",
      "model_saved\n",
      "Epoch [62/100], Loss: 0.04781020116303662\n",
      "model_saved\n",
      "Epoch [63/100], Loss: 0.047793915150960126\n",
      "model_saved\n",
      "Epoch [64/100], Loss: 0.047786963531741396\n",
      "model_saved\n",
      "Epoch [65/100], Loss: 0.04776686613208308\n",
      "model_saved\n",
      "Epoch [66/100], Loss: 0.04777210447421534\n",
      "Epoch [67/100], Loss: 0.04774359316816887\n",
      "model_saved\n",
      "Epoch [68/100], Loss: 0.04773304071156035\n",
      "model_saved\n",
      "Epoch [69/100], Loss: 0.047757998565424245\n",
      "Epoch [70/100], Loss: 0.047706185806700385\n",
      "model_saved\n",
      "Epoch [71/100], Loss: 0.0476912849306672\n",
      "model_saved\n",
      "Epoch [72/100], Loss: 0.04767303442861581\n",
      "model_saved\n",
      "Epoch [73/100], Loss: 0.04768617747879378\n",
      "Epoch [74/100], Loss: 0.047666188472038566\n",
      "model_saved\n",
      "Epoch [75/100], Loss: 0.04765615690232585\n",
      "model_saved\n",
      "Epoch [76/100], Loss: 0.047662815558405576\n",
      "Epoch [77/100], Loss: 0.0476662479705065\n",
      "Epoch [78/100], Loss: 0.04766799375135755\n",
      "Epoch [79/100], Loss: 0.047639252595203026\n",
      "model_saved\n",
      "Epoch [80/100], Loss: 0.0476153437078533\n",
      "model_saved\n",
      "Epoch [81/100], Loss: 0.04760088849242425\n",
      "model_saved\n",
      "Epoch [82/100], Loss: 0.047627275843015515\n",
      "Epoch [83/100], Loss: 0.04762132727641139\n",
      "Epoch [84/100], Loss: 0.0476559503398326\n",
      "Epoch [85/100], Loss: 0.04764695299777175\n",
      "Epoch [86/100], Loss: 0.04760074782934562\n",
      "model_saved\n",
      "Epoch [87/100], Loss: 0.047618749932194865\n",
      "Epoch [88/100], Loss: 0.047583330518199005\n",
      "model_saved\n",
      "Epoch [89/100], Loss: 0.04760113167986031\n",
      "Epoch [90/100], Loss: 0.04756599207217608\n",
      "model_saved\n",
      "Epoch [91/100], Loss: 0.0475355763221918\n",
      "model_saved\n",
      "Epoch [92/100], Loss: 0.04755582951361174\n",
      "Epoch [93/100], Loss: 0.047543373253160076\n",
      "Epoch [94/100], Loss: 0.04751330315278\n",
      "model_saved\n",
      "Epoch [95/100], Loss: 0.04756356813074226\n",
      "Epoch [96/100], Loss: 0.04754791918577754\n",
      "Epoch [97/100], Loss: 0.04751849404448213\n",
      "Epoch [98/100], Loss: 0.04754209361745936\n",
      "Epoch [99/100], Loss: 0.04752004308268088\n",
      "Epoch [100/100], Loss: 0.04753232691042635\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LSTMmodel(3,10).to(device)\n",
    "def saveModel():\n",
    "    torch.save(model.state_dict(), f'model/push_lstm_train.pt')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=1e-2)\n",
    "scheduler = CosineAnnealingLR(optimizer,T_max= 25, eta_min=1e-4)\n",
    "# 학습 루프\n",
    "epochs = 100\n",
    "min_loss = 1e+10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x, y in push_dataloader:\n",
    "        input = x.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파\n",
    "        output = model(input)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(output,y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    mean_loss =running_loss / len(push_dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(push_dataloader)}\")\n",
    "    if min(mean_loss,min_loss) == mean_loss:\n",
    "        min_loss = mean_loss\n",
    "        print('model_saved')\n",
    "        saveModel()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape: torch.Size([41094, 10, 3])\n",
      "y_data shape: torch.Size([41094, 3])\n",
      "Sample input (X): tensor([[-1.4080, -0.3408, -0.3880],\n",
      "        [-1.3444, -0.3299, -0.3081],\n",
      "        [-0.8638, -0.3230, -0.2960],\n",
      "        [-0.6148, -0.2317, -0.2975],\n",
      "        [-0.0057, -0.1466, -0.2956],\n",
      "        [ 0.1462,  0.1466,  0.2956],\n",
      "        [ 0.0057,  0.4976,  0.5859],\n",
      "        [ 0.2159,  0.7773,  0.7419],\n",
      "        [ 0.7244,  0.7673,  0.7526],\n",
      "        [ 0.8696,  0.9860,  0.7545]])\n",
      "Sample output (y): tensor([0.5132, 0.5885, 0.2287])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import torch\n",
    "\n",
    "# CSV 파일 경로 리스트 (001.csv부터 101.csv까지)\n",
    "lunge_file_paths = glob.glob('lunge_csv_data/*.csv')  # 'path_to_files/'는 파일들이 저장된 디렉토리 경로입니다.\n",
    "\n",
    "# 슬라이딩 윈도우 크기\n",
    "window_size = 10\n",
    "stride = 1\n",
    "\n",
    "# 입력 데이터와 출력 데이터 저장 리스트\n",
    "lunge_X_data = []\n",
    "lunge_y_data = []\n",
    "\n",
    "# 각 파일을 처리\n",
    "for file_path in lunge_file_paths:\n",
    "    # 파일 읽기\n",
    "    df = pd.read_csv(file_path, header=None, names=['frame', 'node_id', 'x', 'y', 'z'])\n",
    "    \n",
    "    # node_id 별로 데이터 그룹화\n",
    "    for node_id in df['node_id'].unique():\n",
    "        node_data = df[df['node_id'] == node_id].set_index('frame')[['x', 'y', 'z']]\n",
    "\n",
    "        # 슬라이딩 윈도우 적용\n",
    "        for start in range(0, len(node_data) - window_size):\n",
    "            end = start + window_size\n",
    "            # 입력값 (슬라이딩 윈도우)\n",
    "            window_input = node_data.iloc[start:end].values.astype('float64')\n",
    "\n",
    "            # 윈도우 별로 정규화\n",
    "            scaler = RobustScaler()\n",
    "            scaler_fitted =  scaler.fit(window_input)\n",
    "            window_input_normalized = scaler_fitted.transform(window_input)  # 각 윈도우별로 정규화\n",
    "            \n",
    "            # 출력값 (다음 시점의 (x, y, z) 값)\n",
    "            next_point = node_data.iloc[end].astype('float64')\n",
    "\n",
    "            lunge_X_data.append(window_input_normalized)\n",
    "            lunge_y_data.append(next_point.values)\n",
    "        \n",
    "# X_data는 입력값 (슬라이딩 윈도우)\n",
    "# y_data는 출력값 (다음 시점의 (x, y, z))\n",
    "\n",
    "# numpy 배열로 변환\n",
    "lunge_X_data = torch.FloatTensor(np.array(lunge_X_data))\n",
    "lunge_y_data = torch.FloatTensor(np.array(lunge_y_data))\n",
    "\n",
    "print(\"X_data shape:\", lunge_X_data.shape)\n",
    "print(\"y_data shape:\", lunge_y_data.shape)\n",
    "\n",
    "# 결과 예시 (슬라이딩 윈도우의 첫 번째와 두 번째 샘플)\n",
    "print(\"Sample input (X):\", lunge_X_data[0])\n",
    "print(\"Sample output (y):\", lunge_y_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunge_train = TensorDataset(lunge_X_data,lunge_y_data)\n",
    "lunge_dataloader = DataLoader(lunge_train, batch_size = 256, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.10454150030146474\n",
      "model_saved\n",
      "Epoch [2/100], Loss: 0.05170457745375841\n",
      "model_saved\n",
      "Epoch [3/100], Loss: 0.05154399013852481\n",
      "model_saved\n",
      "Epoch [4/100], Loss: 0.051334610393976576\n",
      "model_saved\n",
      "Epoch [5/100], Loss: 0.05105413235029819\n",
      "model_saved\n",
      "Epoch [6/100], Loss: 0.05079250205423891\n",
      "model_saved\n",
      "Epoch [7/100], Loss: 0.05061901879051457\n",
      "model_saved\n",
      "Epoch [8/100], Loss: 0.05048325744613728\n",
      "model_saved\n",
      "Epoch [9/100], Loss: 0.05034857654006955\n",
      "model_saved\n",
      "Epoch [10/100], Loss: 0.05020266599513544\n",
      "model_saved\n",
      "Epoch [11/100], Loss: 0.05003212915837579\n",
      "model_saved\n",
      "Epoch [12/100], Loss: 0.049849505727150425\n",
      "model_saved\n",
      "Epoch [13/100], Loss: 0.0496887691226435\n",
      "model_saved\n",
      "Epoch [14/100], Loss: 0.04952642458103458\n",
      "model_saved\n",
      "Epoch [15/100], Loss: 0.04935422716720134\n",
      "model_saved\n",
      "Epoch [16/100], Loss: 0.049197724707979965\n",
      "model_saved\n",
      "Epoch [17/100], Loss: 0.04904701296957383\n",
      "model_saved\n",
      "Epoch [18/100], Loss: 0.048903993753172594\n",
      "model_saved\n",
      "Epoch [19/100], Loss: 0.04876346629899666\n",
      "model_saved\n",
      "Epoch [20/100], Loss: 0.04862593179742187\n",
      "model_saved\n",
      "Epoch [21/100], Loss: 0.04849968914243375\n",
      "model_saved\n",
      "Epoch [22/100], Loss: 0.04838601972977197\n",
      "model_saved\n",
      "Epoch [23/100], Loss: 0.04830649788404659\n",
      "model_saved\n",
      "Epoch [24/100], Loss: 0.048180861543192996\n",
      "model_saved\n",
      "Epoch [25/100], Loss: 0.04809512254082083\n",
      "model_saved\n",
      "Epoch [26/100], Loss: 0.0479588199187047\n",
      "model_saved\n",
      "Epoch [27/100], Loss: 0.04787961491354689\n",
      "model_saved\n",
      "Epoch [28/100], Loss: 0.04777131546057344\n",
      "model_saved\n",
      "Epoch [29/100], Loss: 0.047701814900273865\n",
      "model_saved\n",
      "Epoch [30/100], Loss: 0.04761851157831109\n",
      "model_saved\n",
      "Epoch [31/100], Loss: 0.047573350983099165\n",
      "model_saved\n",
      "Epoch [32/100], Loss: 0.047505280847505015\n",
      "model_saved\n",
      "Epoch [33/100], Loss: 0.04737930534326512\n",
      "model_saved\n",
      "Epoch [34/100], Loss: 0.047389697254583335\n",
      "Epoch [35/100], Loss: 0.047381374458579914\n",
      "Epoch [36/100], Loss: 0.047293898556959924\n",
      "model_saved\n",
      "Epoch [37/100], Loss: 0.04731309391349924\n",
      "Epoch [38/100], Loss: 0.04715366817733146\n",
      "model_saved\n",
      "Epoch [39/100], Loss: 0.04718117709763302\n",
      "Epoch [40/100], Loss: 0.04709175829515324\n",
      "model_saved\n",
      "Epoch [41/100], Loss: 0.04710855989815285\n",
      "Epoch [42/100], Loss: 0.047029916359030685\n",
      "model_saved\n",
      "Epoch [43/100], Loss: 0.047039051424503694\n",
      "Epoch [44/100], Loss: 0.046893113385307494\n",
      "model_saved\n",
      "Epoch [45/100], Loss: 0.04690722875320208\n",
      "Epoch [46/100], Loss: 0.046784343383049376\n",
      "model_saved\n",
      "Epoch [47/100], Loss: 0.04681746292604793\n",
      "Epoch [48/100], Loss: 0.04677795210957342\n",
      "model_saved\n",
      "Epoch [49/100], Loss: 0.04670835115154338\n",
      "model_saved\n",
      "Epoch [50/100], Loss: 0.04658431560958024\n",
      "model_saved\n",
      "Epoch [51/100], Loss: 0.04651918191671001\n",
      "model_saved\n",
      "Epoch [52/100], Loss: 0.04650221590346061\n",
      "model_saved\n",
      "Epoch [53/100], Loss: 0.04663813115323182\n",
      "Epoch [54/100], Loss: 0.046606809942063336\n",
      "Epoch [55/100], Loss: 0.04647411935910675\n",
      "model_saved\n",
      "Epoch [56/100], Loss: 0.046407553268978316\n",
      "model_saved\n",
      "Epoch [57/100], Loss: 0.04651040067861539\n",
      "Epoch [58/100], Loss: 0.0463796360186816\n",
      "model_saved\n",
      "Epoch [59/100], Loss: 0.0464208217927758\n",
      "Epoch [60/100], Loss: 0.04642299767467917\n",
      "Epoch [61/100], Loss: 0.04635604066045388\n",
      "model_saved\n",
      "Epoch [62/100], Loss: 0.046435652173453974\n",
      "Epoch [63/100], Loss: 0.046415618215890034\n",
      "Epoch [64/100], Loss: 0.046302666228195156\n",
      "model_saved\n",
      "Epoch [65/100], Loss: 0.046253995952537715\n",
      "model_saved\n",
      "Epoch [66/100], Loss: 0.04616455819388354\n",
      "model_saved\n",
      "Epoch [67/100], Loss: 0.04623396943398514\n",
      "Epoch [68/100], Loss: 0.04625277941965539\n",
      "Epoch [69/100], Loss: 0.046381536275379776\n",
      "Epoch [70/100], Loss: 0.046290654099043115\n",
      "Epoch [71/100], Loss: 0.04630553264818762\n",
      "Epoch [72/100], Loss: 0.04640632292822651\n",
      "Epoch [73/100], Loss: 0.04618503021434968\n",
      "Epoch [74/100], Loss: 0.0462803375091612\n",
      "Epoch [75/100], Loss: 0.04634725268328597\n",
      "Epoch [76/100], Loss: 0.046389201343614864\n",
      "Epoch [77/100], Loss: 0.046353317629430235\n",
      "Epoch [78/100], Loss: 0.04630360121821395\n",
      "Epoch [79/100], Loss: 0.046149555778836615\n",
      "model_saved\n",
      "Epoch [80/100], Loss: 0.04623975622126405\n",
      "Epoch [81/100], Loss: 0.04606429794629723\n",
      "model_saved\n",
      "Epoch [82/100], Loss: 0.046177719748631024\n",
      "Epoch [83/100], Loss: 0.046082182035359166\n",
      "Epoch [84/100], Loss: 0.04601356276073811\n",
      "model_saved\n",
      "Epoch [85/100], Loss: 0.04609648826653543\n",
      "Epoch [86/100], Loss: 0.045870365430340634\n",
      "model_saved\n",
      "Epoch [87/100], Loss: 0.04596122975536385\n",
      "Epoch [88/100], Loss: 0.0458286257854067\n",
      "model_saved\n",
      "Epoch [89/100], Loss: 0.045826812303677106\n",
      "model_saved\n",
      "Epoch [90/100], Loss: 0.04586887853625028\n",
      "Epoch [91/100], Loss: 0.04571606847602203\n",
      "model_saved\n",
      "Epoch [92/100], Loss: 0.04572870324926902\n",
      "Epoch [93/100], Loss: 0.0457769953732535\n",
      "Epoch [94/100], Loss: 0.045721877192766026\n",
      "Epoch [95/100], Loss: 0.04561122709318348\n",
      "model_saved\n",
      "Epoch [96/100], Loss: 0.04565431957960314\n",
      "Epoch [97/100], Loss: 0.04558045923223962\n",
      "model_saved\n",
      "Epoch [98/100], Loss: 0.045653840937645906\n",
      "Epoch [99/100], Loss: 0.045628586940189696\n",
      "Epoch [100/100], Loss: 0.045634280103519095\n"
     ]
    }
   ],
   "source": [
    "model = LSTMmodel(3,10).to(device)\n",
    "def saveModel():\n",
    "    torch.save(model.state_dict(), f'model/lunge_lstm_train.pt')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=1e-2)\n",
    "scheduler = CosineAnnealingLR(optimizer,T_max= 25, eta_min=1e-4)\n",
    "# 학습 루프\n",
    "epochs = 100\n",
    "min_loss = 1e+10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x, y in lunge_dataloader:\n",
    "        input = x.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파\n",
    "        output = model(input)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(output,y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    mean_loss =running_loss / len(lunge_dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(lunge_dataloader)}\")\n",
    "    if min(mean_loss,min_loss) == mean_loss:\n",
    "        min_loss = mean_loss\n",
    "        print('model_saved')\n",
    "        saveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OldJins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
