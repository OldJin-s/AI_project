{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 운동 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorchtools import EarlyStopping\n",
    "from gcn_source import PoseGCN\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 정의 (프레임 단위로 처리)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 프레임 크기 조정\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화 (ImageNet 기준)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ExerciseDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, frames_per_video=16):\n",
    "        \"\"\"\n",
    "        :param root_dir: 데이터 폴더의 최상위 디렉토리 (예: \"data/\")\n",
    "        :param transform: 영상 데이터에 적용할 변환 함수\n",
    "        :param frames_per_video: 영상에서 추출할 프레임 수\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.frames_per_video = frames_per_video\n",
    "\n",
    "        # 클래스별 라벨 설정\n",
    "        self.classes = {\n",
    "            \"push_start\": [1, 0, 0],\n",
    "            \"squat_start\": [0, 1, 0],\n",
    "            \"lunge_start\": [0, 0, 1]\n",
    "        }\n",
    "\n",
    "        # 모든 영상 파일의 경로와 라벨 저장\n",
    "        self.video_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for class_name, label in self.classes.items():\n",
    "            class_folder = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_folder):\n",
    "                for file in os.listdir(class_folder):\n",
    "                    if file.endswith('.mp4'):  # MP4 파일만 처리\n",
    "                        self.video_paths.append(os.path.join(class_folder, file))\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        # 영상 읽기 및 프레임 추출\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        while len(frames) < self.frames_per_video:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:  # 영상이 끝났으면 루프 중단\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # OpenCV는 BGR로 읽으므로 RGB로 변환\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # 프레임 수가 부족할 경우 반복하여 채움\n",
    "        while len(frames) < self.frames_per_video:\n",
    "            frames.append(frames[-1])  # 마지막 프레임을 반복해서 추가\n",
    "\n",
    "        # 텐서 변환 및 전처리\n",
    "        frames = torch.tensor(frames, dtype=torch.float32).permute(0, 3, 1, 2)  # (T, H, W, C) → (T, C, H, W)\n",
    "        if self.transform:\n",
    "            frames = self.transform(frames)\n",
    "\n",
    "        return frames, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로 설정\n",
    "root_dir = \"data\"\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = ExerciseDataset(root_dir, transform=transform, frames_per_video=16)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# 데이터 확인\n",
    "for batch_idx, (videos, labels) in enumerate(data_loader):\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(f\"Videos shape: {videos.shape}\")  # (Batch, T, C, H, W)\n",
    "    print(f\"Labels shape: {labels.shape}\")  # (Batch, Class)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 데이터가 저장된 폴더 경로\n",
    "video_folder = 'data'\n",
    "\n",
    "# 데이터셋 객체 생성\n",
    "dataset = ExerciseDataset(video_folder, transform=transform)\n",
    "\n",
    "# 데이터 로더 객체 생성 (배치 크기 32, 셔플 활성화)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 데이터 로더를 사용하여 배치 단위로 데이터 확인\n",
    "for videos, labels in data_loader:\n",
    "    print(videos.shape, labels.shape)\n",
    "    break  # 한 배치만 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = PoseGCN().to(device)\n",
    "optimizer = optim.RAdam(model.parameters(),lr = 1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0.0001)\n",
    "def saveModel():\n",
    "    torch.save(model.state_dict(), f'model/classifying.pt')\n",
    "loss_ = []\n",
    "valoss_ = []\n",
    "logger = {\"train_loss\": list(),\n",
    "          \"validation_loss\": list(),\n",
    "\n",
    "          }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs) :\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_train_loss = 0.0\n",
    "        running_vall_loss = 0.0\n",
    "        total = 0\n",
    "        model.train()\n",
    "        for data in train_x:\n",
    "            inputs = data\n",
    "            outputs = data\n",
    "\n",
    "            optimizer.zero_grad()  # zero the parameter gradients\n",
    "            encoded, predicted_outputs = model((inputs))  # predict output from the model\n",
    "            train_loss = criterion(predicted_outputs, outputs)# calculate loss for the predicted output\n",
    "\n",
    "            train_loss.backward()  # backpropagate the loss\n",
    "            optimizer.step()  # adjust parameters based on the calculated gradients\n",
    "            running_train_loss += train_loss.item()  # track the loss value\n",
    "\n",
    "        loss_.append(running_train_loss / n)\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for data in valid_x:\n",
    "                inputs = data\n",
    "                outputs = data\n",
    "\n",
    "                encoded, predicted_outputs = model((inputs))\n",
    "                val_loss = criterion(predicted_outputs, outputs)\n",
    "\n",
    "                # The label with the highest value will be our prediction\n",
    "                _, predicted = torch.max(predicted_outputs, 1)\n",
    "                running_vall_loss += val_loss.item()\n",
    "                total += outputs.size(0)\n",
    "                val_loss_value = running_vall_loss / len(valid_x)\n",
    "\n",
    "\n",
    "        valoss_.append(val_loss_value)\n",
    "\n",
    "        avgtrainloss = np.mean(loss_)\n",
    "        avgvalidloss = np.mean(valoss_)\n",
    "        print('epoch', epoch + 1)\n",
    "        print(f'train loss : {avgtrainloss}, validation loss : {avgvalidloss}')\n",
    "        early_stopping(avgvalidloss, model)\n",
    "        if early_stopping.early_stop:  # 조건 만족 시 조기 종료\n",
    "            break\n",
    "    saveModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldjins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
